\documentclass{article}
\usepackage{./nips15submit_e,amsmath,amsthm,graphicx,subfig,flafter}
%\usepackage{amsmath,amssymb,enumerate,mathtools}

\newcommand{\eqnref}[1]{equation \eqref{eq:#1}}
\newcommand{\Eqnref}[1]{Equation \eqref{eq:#1}}
\newcommand{\secref}[1]{section \ref{sec:#1}}
\newcommand{\Secref}[1]{Section \ref{sec:#1}}
\newcommand{\thref}[1]{Theorem \ref{th:#1}}
\newcommand{\figref}[1]{figure \ref{fig:#1}}
\newcommand{\Figref}[1]{Figure \ref{fig:#1}}

\newcommand{\tightframe}[1]{{\setlength{\fboxsep}{0pt}\setlength{\fboxrule}{1pt}\fbox{#1}}}

\newtheorem{theorem}{Theorem}

\title{Private Attribution Networks}
\author{
Maxwell Anselm\\
Lehigh University\\
Bethlehem, PA 18015\\
\texttt{mba210@lehigh.edu}\\
}

\nipsfinalcopy
\begin{document}
\maketitle

\section{Introduction}

motivation, summary, takeaway

Peer-to-peer (P2P) networks are a common tool for sharing information. Most P2P
architectures are completely open: the identities of the participants and the
data being shared in the network are available to the public. When privacy is
applied to P2P networks, it is usually done in a way that completely closes down
the network: by making membership in the network invite-only\cite{privatep2p}.

We define a new kind of privacy for P2P networks called ``attribution privacy''
which exists in a traditional open network. Attribution privacy formalizes
the notion that sharing public information among public peers can still leak
private information. We give examples of both real world and technical
applications where attribution privacy is a concern. We also classify when
attribution privacy leaks can occur and measure the potential risk to peers
participating in such a network.

We consider a couple modifications that can be made to the P2P protocol in order
to mitigate the attribution privacy leaks, and measure their efficacy as well as
their performance impact. Lastly we define a private attribution network, which
combines these methods to provide a balance of privacy and performance.

\section{Related Work}

XRay, Chord (P2P), TOR, BitTorrent

\section*{Main sections follow}

solution, implementation, main challenges overcome

\section{Definitions}

We first define what information sharing means in our P2P network. We
imagine a P2P network in which there are a fixed number of peers (the
swarm) and all peers are aware of the other members of the swarm via some
central authority (the tracker). These peers exchange messages via some secure
channel such as HTTPS (perhaps using public keys synchronised through the
tracker). Thus which peers are communicating with which is public information,
while the contents of those messages is kept private from an observer.

Let $\mathcal{Q}$ be a set of public queries and let $\mathcal{D}$ be a set of
public data about those queries. Intuitively, the elements of $\mathcal{Q}$
represent the queries that a peer might make to other peers in the swarm, and
$\mathcal{D}$ represents potential responses to those queries. Then we define a
function $K:\mathcal{Q}\rightarrow 2^\mathcal{D}$ which maps queries to the set
of possible responses to each query i.e. $\forall q\in\mathcal{Q},
K(q)\subseteq\mathcal{D}$. The reason why peers participate in the network is to
learn more about the ``knowledge function'' $K$. For example, we can imagine
$\mathcal{Q}$ as a set of file names and $\mathcal{D}$ as a set of file
fragments; then $K$ indicates which fragments correspond to which file names (and
which are reused across multiple file names), so determining the value of $K(q)$
amounts to downloading file $q$. Formally, a response $D\subseteq\mathcal{D}$ to
a query $q\in\mathcal{Q}$ indicates that $D\subseteq K(q)$.

Next we define $\mathcal{S}$ to be the set of original sources of knowledge
about $K$ in the network. If a peer possesses some source $s\in\mathcal{S}$,
then they can receive some information $D_s\subseteq K(q_s)$ {\it without}
querying another peer in the network. In this case we say that the peer {\it
originates} (or is the {\it origin} of) $D_s\subseteq K(q_s)$. We assume that
the network is otherwise closed, so if a peer wants to learn about $K(q)$ for
some $q$, there need to be peers in the network with sources pertaining to $q$.

For attribution privacy to come into play we need two conditions to hold:
\begin{enumerate}
	\item The sources must be private. That is, a peer with access to some
		$s\in\mathcal{S}$ does not want it to be known publicly.
	\item The relationship between $D_s\subseteq K(q_s)$ and $s\in\mathcal{S}$
		must be public. That is, a peer who sees the response $D\subseteq K(q)$
		will know which sources in $\mathcal{S}$ it might have originated from.
\end{enumerate}

If these conditions hold, then it is possible for a public peer to share public
data about a public query, and in doing so inadvertently communicate information
about its private sources. That is an attribution privacy leak.

\section{Applications}\label{sec:example}

\subsection{Nickelback}

A simple (somewhat facetious) example is of a small town in which no one likes
the Canadian rock band Nickelback. Here we imagine the townspeople as peers in
the P2P network. If you (being a huge Nickelback fan) were to move to this town,
you might find yourself in the uncomfortable situation where a Nickelback song
comes on the radio and people are curious what the name is and who performs it.
In this situation, $\mathcal{S}$ contains the property ``being a Nickelback
fan'' (a source of knowledge about Nickelback songs). $\mathcal{Q}$ contains the
unidentified song on the radio, $\mathcal{D}$ contains song names, and $K$ maps
the unidentified song to the correct name. The curious members of the town query
for name of the song, and you would honestly like to provide it.

However, being that you are the only Nickelback fan in town, doing so would
prove to whomever you tell that you {\it originate} the knowledge of the correct
song name. The townspeople would be able to apply their public knowledge of the
sources to discover your private information: namely that a person who knows the
name of a random Nickelback song is probably a Nickelback fan. By honestly
providing the requested data, you have inadvertently revealed your private
source. This is a P2P network where private attribution is needed.

\subsection{XRay}

For a more technical example, consider the tool XRay\cite{xray}. XRay audits
online advertisements to reverse-engineer the ad targeting criteria and thus
determine if a company is exploiting one's sensitive information. It does this
using a complicated system of data duplication and fake account management, but
the authors note that ``a collaborative approach to auditing, in which users
contribute their [data] in a privacy-preserving way is a promising
direction...'' In such a system, users would participate in a P2P network where
they freely share which ads they have seen and in association with which
personal information. Then the network could collaborate to determine the ad
targeting criteria.

In this situation, $\mathcal{Q}$ is the set of online ads, $\mathcal{D}$ is the
set of personal information that might be targeted, and $K$ represents the ad
targeting criteria i.e. which personal data are targeted by which ads.
Interestingly, the private sources $\mathcal{S}$ in this case are identical to
$\mathcal{D}$: if you originate the knowledge that a particular ad targets
particular data, then informing others of that association also divulges that
you possess the targeted data. Such a P2P network must consider its members'
attribution privacy.

\section{Privacy Risk}\label{sec:prrsk}
\subsection{Baseline}\label{sec:baseline}

To measure the attribution privacy risk in a P2P network, we start by
considering the worst-case scenario. Suppose that for knowledge about some $q$
there is only a single source $s$, only a single peer $x$ with access to that
source (i.e. a single origin), and that $x$ has not shared any knowledge of $q$
with the rest of the network. Another peer $y$ who wants to learn about $K(q)$
might then query {\it every peer} in the network for knowledge about $q$. Since
$x$ has not previously shared information about $q$, every peer will respond
with no knowledge except for $x$.

$y$ now knows that of all the peers, only $x$ has knowledge about $q$. Because
the network is closed, $y$ also knows that there must be a source for $q$ among
the peers who know about $q$. Thus $x$ must possess a source for $q$ and since
we assumed there was only one such source, it must be $s$. Thus by sharing their
knowledge about $q$, $x$ has inadvertently shared the fact that they possess
source $s$.

We can reason that this is the worst possible case as follows: if there were
multiple sources related to $q$, then $y$ would only know that $x$ possesses one
of those sources; it would not necessarily know which one. Also, if there were
multiple peers with access to a source for $q$, then multiple peers would
respond when $y$ queries every peer about $q$. The same would occur if $x$ had
previously shared knowledge about $q$ with other peers in the network. In both
of these cases we can quantify the information gained by $y$. Let $S$ be the
event that one of the peers is an origin for $q$ (i.e. has
source $s$) and let $H$ be the number of peers who have the knowledge and thus
respond to the query.
If $k$ peers respond to the query, then we can express $P(S|H=k)$ in terms of
$P(S)$, the prior probability of a peer being an origin:
\begin{align}
	P(S|H=k)&=P(S|\text{one of the $k$ is a source})=\frac{P(S\cap\text{one of
	the $k$ is a source})}{P(\text{one of the $k$ is a source})}\nonumber\\
	&=\frac{P(S)}{1-P(\text{none of the $k$ are sources})}\label{eq:psksub}\\
	&=\frac{P(S)}{1-(1-P(S))^k}\label{eq:psk}
\end{align}
Note that we can simplify to \eqref{eq:psksub} because the event $S$ is included
in the event that one of the $k$ responders is a source. Note also that
$P(S|H=k)>P(S)$ for $P(S)\in(0,1)$. When $k=1$ (which is our previous assumption
that there is only one origin), $P(S|H=k)=1$ which agrees with our reasoning
that $y$ knows definitively that $x$ has source $s$. However if more than one peer
responds (either by multiple sources or by $x$ sharing knowledge), $y$ cannot be
certain whether $x$ has a source.

Going back to our original worst-case assumptions, suppose that after $y$
queries, another peer $z$ queries for information about $q$. Now we are in the
previously discussed weaker case: {\it two} peers will respond with knowledge
about $q$ ($x$ and $y$)! Thus $z$'s information about $s$ is only $P(S|H=2)<1$.

\begin{theorem}
	If $k$ peers in the network have knowledge of $q$, then
	\begin{equation*}
		P(S|\text{the peer responds to a query})\le P(S|H=k)
	\end{equation*}
\end{theorem}
\begin{proof}
	This follows from the definition in \eqnref{psk} and the previous arguments.
\end{proof}

The goal of a private attribution network is to make $P(S|\text{the peer
responds to a query})$ smaller than $P(S|H=k)$.

\subsection{Unreliable Peers}\label{sec:unreliable}

One simple approach to improving the privacy of the network is for the peers to be
unreliable i.e. let $P(\text{respond to a query about }q|\text{have knowledge of
}q)=r<1$. Now when $y$ queries the entire network, they can no longer be sure
that the peers who respond are all the peers who have the relevant knowledge.
Thus we now have a new random variable $M\ne H$ which is the number of peers who
respond to a query about $q$.

If $m$ peers respond to a query, in order to calculate the posterior, $y$ must
consider how many peers in the network actually have knowledge about $q$, which
can range from $m$ to $n-1$ (since $y$ does not know about $q$).
\begin{align}
	P(S|M=m)&=\sum_{k=m}^{n-1}P(S\cap H=k|M=m)\nonumber\\
	&=\sum_{k=m}^{n-1}\frac{P(S\cap H=k\cap M=m)}{P(M=m)}\frac{P(H=k\cap
	M=m)}{P(H=k\cap M=m)}\nonumber\\
	&=\sum_{k=m}^{n-1}P(S|H=k\cap M=m)P(H=k|M=m)\nonumber\\
	&=\sum_{k=m}^{n-1}P(S|H=k)\frac{P(M=m|H=k)P(H=k)}{P(M=m)}\label{eq:psmsimp}\\
	&=\frac{1}{P(M=m)}\sum_{k=m}^{n-1}P(S|H=k)P(M=m|H=k)P(H=k)\label{eq:psmbig}
\end{align}
where $P(S|H=k)$ is calculated as in \eqnref{psk} and we can simplify to
\eqref{eq:psmsimp} because $S$ is independent of $M$ if we know $H=k$.
We see that now the posterior probability of a source depends on the prior
distribution of knowledge in the network $H$. We also see the prior probability
of $M$, but this too can be expressed in terms of $H$:
\begin{align*}
	P(M=m)=\sum_{k=m}^{n-1}P(M=m\cap H=k)=\sum_{k=m}^{n-1}P(M=m|H=k)P(H=k)
\end{align*}

Lastly we observe that $P(M=m|H=k)$ is simply given by the binomial
distribution $b(m,k,r)$: the probability of $m$ successes out of $k$ trials where
each trial has probability $r$ of success. Substituting into \eqnref{psmbig} gives us
\begin{equation}\label{eq:psm}
	P(S|M=m)=\frac{\sum_{k=m}^{n-1}P(S|H=k)b(m,k,r)P(H=k)}{\sum_{k=m}^{n-1}b(m,k,r)P(H=k)}
\end{equation}

\begin{theorem}\label{th:rbound}
	$P(S|M=m)\le P(S|H=m)$ and this inequality is strict if $r<1$.
\end{theorem}
\begin{proof}
	Suppose that $r=1$, then $P(H=m)=1$ so \eqnref{psm} simplifies to
	\begin{equation*}
		P(S|M=m)=\frac{P(S|H=m)b(m,m,r)P(H=m)}{b(m,m,r)P(H=m)}=P(S|H=m)
	\end{equation*}
	Now suppose $r<1$, by \eqnref{psk} we have that
	\begin{equation*}
		P(S|H=k+1)=\frac{P(S)}{1-(1-P(S))^{k+1}}<\frac{P(S)}{1-(1-P(S))^k}=P(S|H=k)
	\end{equation*}
	therefore
	\begin{align*}
		P(S|M=m)&=\frac{\sum_{k=m}^{n-1}P(S|H=k)b(m,k,r)P(H=k)}{\sum_{k=m}^{n-1}b(m,k,r)P(H=k)}\\
		&<\frac{\sum_{k=m}^{n-1}P(S|H=m)b(m,k,r)P(H=k)}{\sum_{k=m}^{n-1}b(m,k,r)P(H=k)}\\
		&=P(S|H=m)\frac{\sum_{k=m}^{n-1}b(m,k,r)P(H=k)}{\sum_{k=m}^{n-1}b(m,k,r)P(H=k)}\\
		&=P(S|H=m)
	\end{align*}
\end{proof}

One concern with such a change to the P2P protocol is the potential performance
impact. Smaller $r$ will increase the overall number of queries which need to be
made in order for the knowledge to spread, thus decreasing the overall speed of
the network. This impact is measured empirically in \secref{qgiveni}.

\subsection{Extra Responses}\label{sec:exre}

Since $P(S|H=k)$ decreases as $k$ increases, another method of
preserving privacy would be for the peers responding to queries to force $k$ to
be large. Specifically, whenever a peer responds to a query it also
sends that response to each other peer with probability
$\frac{t}{n-2}$. Since there are $n-2$ peers other than $x$ and $y$, we expect
that $t$ extra responses will be sent.

Applying this change in protocol to our worst-case situation, we see that $y$
still knows with $P(S|H=1)=1$ that $x$ has source $s$. However, afterwards $x$,
$y$, and $t$ random peers are expected to know about $q$ thus the next peer
to make a query has an expected advantage of only $P(S|H=t+2)$. We can minimize this
probability by making $t$ even larger: $t=n-2$ means that $x$ sends extra
responses to every other peer, and then the next peer won't query at all because
every peer already has the data!

But this view is oversimplified. Although this does minimize the posterior
probability of $x$ having $s$ following a query, it just leaks the
information earlier in the process. For example, consider a swarm of just four
peers $x$, $y$, $\beta$, and $\gamma$ and suppose that $t=2$. $y$ starts as usual by
querying every peer about $q$ ($x$, $\beta$, and $\gamma$). Only $x$ has knowledge of
$q$, so it responds to $y$ and sends extra responses with probability
$t/(n-2)=1$ to peers $\beta$ and $\gamma$. From $\beta$'s perspective, since it received a
query about $q$ from $y$, it knows that $x$ and $\gamma$ were also queried. Since a
queried peer always sends extra responses if it has the knowledge, $\beta$ knows that
every peer who sends it an extra response knows about $q$. It received an extra
response only from $x$ thus it can apply the same logic as $y$ (in
\secref{baseline}) to deduce that $x$ has $s$.

Clearly, $t=n-2$ is too large. But even smaller values of $t$ leak some privacy to the
peers receiving extra responses. In fact, the situation generalizes to that of
\secref{unreliable}: when a query about $q$ is received by a peer $\beta$,
they expect to receive an extra response from each peer that has knowledge of
$q$ with probability $t/(n-2)$. It is as if $\beta$ itself made the query and each
peer responds probabilistically, which is exactly the situation with unreliable
peers, only now $r=t/(n-2)$ and $M$ is the number of extra responses received by
$\beta$.

The point of sending out random extra responses would be defeated if
$P(S|M=m)>P(S|H=m)$ because then the extra responses a peer sends out would
actually leak more private information than if it were simply queried directly.
However we showed with \thref{rbound} that $P(S|M=m)<P(S|H=m)$ if $r<1$ i.e. if
$t<n-2$.
To choose $t$, we first note
a major difference from \secref{unreliable}: an attacker in this case
has some control over $r$ and thus $M$. If we have a swarm of $n$ peers,
an attacker can add $b$ malicious peers to the swarm. These malicious peers can
share information among themselves, such as who they have received extra
responses from. In effect, the $b$ peers behave like a single peer that has a
higher chance of receiving extra responses.

\begin{theorem}
	If extra responses are sent with probability $\frac{t}{n-2}$, then the
	probability that an attacker inserting malicious peers into the network
	receives an extra response is bounded by $1-1/e^t$.
\end{theorem}
\begin{proof}
Let $B$ be the event that at least one of the $b$ malicious peers is sent an extra
	response and let $n$ be the original number of peers in the network. Then:
\begin{align*}
	P(B)&=1-P(\neg B)\\
	&=1-\left(1-P(\text{a particular malicious peer gets an extra response})\right)^b\\
	&=1-\left(1-\frac{t}{n+b-2}\right)^b\\
	\lim_{b\rightarrow\infty}P(B)&=1-\frac{1}{e^t}
\end{align*}
\end{proof}
Even for $t=5$ this probability is very close one, so we must choose a small $t$
if we consider such an attack to be viable.  Our only concern with small $t$
might be that it does not cause the knowledge to spread ``quickly enough'' to
provide a privacy benefit. However we will see in \secref{qgiveni} that even for
$t=1$ (which provides a limit of $1-1/e\approx2/3$), knowledge propagates very
quickly through the network.

Note that this leak also relies largely on the assumption that every peer
queries every other peer in order to greedily determine as much private
information as possible. In an actual P2P network, it is not necessary for each
peer to query every other peer. Thus with non-greedy peers, when a peer (or
group of malicious peers) is
{\it not} sent an extra response it is possible that it will also {\it not} receive the
corresponding query for $q$---in which case it will be completely oblivious to the
entire exchange and no leak will occur.

\section{Knowledge Distribution}\label{sec:kdist}

The privacy provided by both techniques from \secref{prrsk} depends on $P(H)$:
the prior probability distribution for the number of peers who possess knowledge
about some query $q$. In this section we will see that $P(H)$ is formulated in
much the same way as $P(S|M)$ from \secref{unreliable} and how the design of the
P2P protocol is crucial to its calculation.

Na\"ively, we could assume that at the time that we query for $q$, no other
peers have made similar queries. In that situation, the peers who
possess knowledge of $q$ would be exactly the set of origins: no queries have
been made, so no knowledge has spread beyond the sources for $q$. Then
\begin{equation*}
	P(H=k|\text{no queries})=P(k\text{ sources}|\text{at least one
	source})
\end{equation*}
since we need to assume sources exist in order to query for $q$. But this will
most likely not be accurate since queries have probably occurred between other
peers, thus changing the distribution of $H$.

However, assuming that our peers greedily query every other peer in the swarm
(in order to gain as much private knowledge as possible), we would know a priori
how many queries have been made for $q$. Thus our prior should really be
$P(H|Q)$ where $Q$ is the number of previously made queries for $q$. Even in the
non-greedy case where peers query some subset of the network, we could use the
number of observed queries to probabilistically calculate the prior.

% TODO link to future work about prob prior?

This prior can be formulated in much the same way as $P(S|M)$ from \eqnref{psm},
except instead of considering possible values of $H$ for $M$, we consider possible
values of $I$ for $Q$, where $I$ is the number of origins that were originally in the network:
\begin{align}
	P(H=k|Q=u)&=\sum_{i=1}^kP(H=k|I=i\cap Q=u)P(I=i|Q=u)\nonumber\\
	&=\frac{\sum_{i=1}^kP(H=k|I=i\cap
	Q=u)P(Q=u|I=i)P(I=i)}{\sum_{i=1}^{k}P(Q=u|I=i)P(I=i)}\label{eq:hgq}
\end{align}
All the terms in this formula can be calculated based on what we already know of
the network. $P(I=i)$, the prior probability of
there being $i$ origins, is simply given by $P(S)$ and the binomial
distribution: $P(I=i)=b(i,n-1,P(S))$. $P(H=k|I=i\cap Q=u)$, the probability of
$k$ peers knowing about $q$ after $i$ origins are queried $u$ times, can
be calculated based on the rate at which knowledge spreads through the network
(see \secref{hgiveniq}). $P(Q=u|I=i)$, the probability that $u$ queries are made
against $i$ origins, can also be calculated using the rate at which
knowledge spreads though from a different perspective (see \secref{qgiveni}).

\subsection{Conditional Knowledge Distribution}\label{sec:hgiveniq}

We showed previously how the distribution of knowledge given a certain number of
queries were made depends on the knowledge distribution also assuming the number
of origins: $P(H|I\cap Q)$.

The calculation of this distribution in effect measures how knowledge flows
through the network given a particular querying protocol. For example, given
the simple case where a peer simply responds to a query deterministically (as
in \secref{baseline}), we know that
\begin{equation*}
	P(H=i+u|I=i\cap Q=u)=1
\end{equation*}
because $i$ peers know initially and each of the $u$ queries passes on the
knowledge to one more peer.

If we have unreliable peers as in \secref{unreliable}, where a peer has
probability $r$ of responding to a query, we can easily calculate cases such as
\begin{align*}
	P(H=i|I=i\cap Q=1)&=(1-r)^i\\
	P(H=i+1|I=i\cap Q=1)&=1-(1-r)^i
\end{align*}
however the general calculation is far more complex as $Q$ increases (due to
multiple ways of achieving the same $H$). It takes the form
\begin{equation*}
	P(H=k|I=i\cap Q=u)=\sum_{\{F\}}\prod_{l=0}^{k-i-1}(1-r)^{(i+l)F_l}(1-(1-r)^{i+l})
\end{equation*}
where the sum is over all possible ways to have exactly $k-i$ successful queries
out of $u$ queries and the $F_l$ represent the number of failures before the
$l^\text{th}$ success. This could be efficiently calculated using dynamic
programming, however in practice we found that simulations of the
network to empirically calculate the probability converged reasonably quickly to
an accurate result (and are much simpler to implement). However we observe that
this calculation only appears in \eqnref{hgq} as a product with $P(Q=u|I=i)$. We
will see in \secref{qgiveni} that $P(Q=u|I=i)$ will only be nonzero for a
limited range of $i$. Thus in practice we need only calculate $P(H=k|I=i\cap
Q=u)$ when this product has a chance of being nonzero. See \secref{pan} for the
result.

Similarly for the case of extra responses from \secref{exre}, the general
probability calculation is surprisingly complex; one must consider which peers
were chosen to receive extra responses and how these peers overlap with each
other and the queried peers. Once again we chose to empirically calculate the
distribution via simulation.

\subsection{Query Distribution}\label{sec:qgiveni}

The second distribution which must be calculated is $P(Q|I)$, the probability of
observing a certain number of queries given a number of initial origins. We
calculate this by taking into account $\Omega$, the number of total queries
about $q$ that will be performed. Since we assume that every peer will
eventually want to learn about $q$, this is equivalent to measuring how many
queries it takes for every peer to have the knowledge.
\begin{equation}\label{eq:pqi}
	P(Q=u|I=i)=\sum_{v=0}^\infty P(Q=u\cap\Omega=v|I=i)
\end{equation}

Consider deterministic responses as in \secref{baseline}. If a peer were to
observe the network over its lifetime, given $i$ origins it would see $n-i-1$
queries: one for each of the peers that does not have the knowledge (not
counting itself). For this protocol, \eqnref{pqi} simplifies to
\begin{equation}\label{eq:pqisimple}
	P(Q=u|I=i)=P(Q=u\cap\Omega=n-i-1|I=i)=\frac{1}{n-i-1}
\end{equation}
for $u\in[1,n-i-1]$. The first equality follows from the fact that there must be
$n-i-1$ queries. The second follows because a priori we can only assume that
each of the $n-i-1$ peers is indistinguishable with respect to wanting knowledge
about $q$, thus each query must be equally likely.

As in the previous section, the calculations are more elaborate as we change the
protocol. For unreliable peers, $P(\Omega|I)$ is similar to a negative binomial
distribution (the number of trials needed to get a certain number of successes
in a Bernoulli process) however it is more complicated because the probability
of a query succeeding increases as more queries succeed. Once again we found it
more practical to simply empirically calculate $P(\Omega|I)$ via network
simulation and then use the same assumption of equally likely queries from
\eqnref{pqisimple} to get $P(Q|I)$.

\begin{figure}%
    \centering
	\subfloat[$P(\Omega|I)$]{{\includegraphics[width=0.5\textwidth]{qdist3d.pdf}}}%
	\subfloat[$P(Q|I)$]{{\includegraphics[width=0.5\textwidth]{qdist3d_final.pdf}}}%
	\caption{Calculating $P(Q|I)$ with unreliable peers ($r=0.25$) via network
	simulation ($n=100$). Each line in (a) shows the distribution
	$P(\Omega|I=i)$ for different $i$, while lines in (b) show $P(Q|I=i)$.}
    \label{fig:unreliable}%
\end{figure}

\Figref{unreliable} shows the result of
calculating $P(\Omega|I)$ and $P(Q|I)$ in this manner for a fixed chance $r$ of
a peer responding. Note that as the number of origins increases, the probability
of a query succeeding approaches 1, thus $P(\Omega=n-i|I=i)\rightarrow 1$,
consequently $P(Q|I)$ approaches a uniform distribution (since this is similar
to the deterministic case of \eqnref{pqisimple}). A convenient byproduct of this
calculation is that we also see the performance impact of the protocol.
Because $P(\Omega|I)$ is also a sort of measure of how long it takes every peer
to learn the knowledge, it is a decent measure of the worst-case performance of
the network. We can see that for a small number of origins, while the smaller
values of $Q$ have the highest probabilities, $P(Q|I)$ has a very long tail,
indicating that in some cases we might require significantly more queries
overall before the knowledge spreads.

\begin{figure}%
    \centering
	\subfloat[$P(\Omega|I)$]{{\includegraphics[width=0.5\textwidth]{qdist3d_er.pdf}}}%
	\subfloat[$P(Q|I)$]{{\includegraphics[width=0.5\textwidth]{qdist3d_er_final.pdf}}}%
	\caption{Calculating $P(Q|I)$ with extra responses ($t=1$) via network
	simulation ($n=100$). The format is the same as \figref{unreliable}.}
    \label{fig:exre}%
\end{figure}

We can use the same technique with a different simulation to find $P(Q|I)$ for
the case of extra responses. \Figref{exre} shows this result for a fixed $t$.
This converges to a uniform distribution more slowly than unreliable peers does,
but note that the scale for $Q$ is much smaller: even for 1 origin, it is
unlikely to take more than 14 queries for the knowledge to spread completely.
This is because each successful query only slightly increases the chance of each
extra response being sent, but overall the number of extra responses causes the
knowledge to spread throughout the network at an exponential rate. This
alleviates our concern of using small $t$ that we had from \secref{exre}.

\begin{figure}%
    \centering
	\subfloat[$P(\Omega|I)$]{{\includegraphics[width=0.5\textwidth]{qdist3d_uer.pdf}}}%
	\subfloat[$P(Q|I)$]{{\includegraphics[width=0.5\textwidth]{qdist3d_uer_final.pdf}}}%
	\caption{Calculating $P(Q|I)$ with unreliable peers and extra responses
	($r=0.25$, $t=1$) via network simulation ($n=100$). The format is the same
	as \figref{unreliable}.}
    \label{fig:uexre}%
\end{figure}

Because these calculations are done empirically, it is straightforward to extend this to
the combination of the two techniques: unreliable peers where each peer sends
extra responses. The result is shown in \figref{uexre}. As we might expect, the
resulting distribution exhibits a mix of those from figures \ref{fig:unreliable}
and \ref{fig:exre}: slow convergence to a uniform distribution with a moderately
long tail.

% TODO does this mix turn out to be good?

\section{Evaluation}\label{sec:pan}

How well does it work?

With the calculations developed in the previous sections, we can finally
implement a private attribution network using the protocol changes from sections
\ref{sec:unreliable} and \ref{sec:exre} and measure the resulting private
knowledge leakage. We must do so empirically because of the empirical
calculations in \secref{kdist}.

\begin{figure}%
    \centering
	\includegraphics[width=0.75\textwidth]{comp.pdf}
	\caption{Comparison of different network protocols in terms of private
	information leakage. Each peer is numbered in the order that it first
	acquires knowledge via successfully querying for $q$. A point on a line
	represents the private information gained by a particular peer at the time
	it queries (in terms of the posterior probability on $S$). Note the
	logarithmic scale on the $X$ axis. The parameters used were $n=100$,
	$r=0.25$, $t=1$.}
    \label{fig:comp}%
\end{figure}

We chose to evaluate the worst case scenario (similar to \secref{baseline}): a
single query $q$ with a single source $s$ possessed by a single peer $x$. Then
for multiple iterations we simulated knowledge of $q$ spreading through the
network query-by-query, recording after each query the private information leak
in terms of $P(S|\text{$x$ responds to a query})$. However since some of the protocols
depend on random behavior, the leakage can depend on the specific
random choices made by different peers in the network (e.g. whether a peer
chooses to respond, how many peers it chooses to send extra responses to). Thus
we run several thousand network simulations and average out the leakage per
query. \Figref{comp} shows the results of these simulations for four different
protocols.

The ``Worst case'' line is the leakage in the simple deterministic case from
\secref{baseline} where each peer with the relevant knowledge responds to the
query. Here the leakage is simply given by $P(S|H=k)$ e.g. the first peer to
query for the knowledge has $P(S|\text{response})=1$, the next peer has
$P(S|\text{response})\approx 0.5$, etc.

The ``Unreliable peers'' line represents the leakage with unreliable peers as in
\secref{unreliable}. The information leakage in this case is significantly lower
in the 

We observe that the three other
protocols provide lower information leakage according to this chart (as we would
hope!) which indicates that they are all viable attribution privacy methods.

\section{Discussion \& Conclusion}

\subsection{Future Work}

\begin{thebibliography}{9}

\bibitem{xray}
	M. L\'ecuyer, G. Ducoffe, F. Lan, A. Papancea, T. Petsios, R. Spahn, A. Chaintreau, and R. Geambasu.
	XRay: Enhancing the Web's Transparency with Differential Correlation.
	\emph{USENIX Security}, 2014.

\bibitem{privatep2p}
	M. Rogers, S. Bhatti.
	How to Disappear Completely: A Survey of Private Peer-to-Peer Networks.
	\emph{Sustaining Privacy in Autonomous Collaborative Environments (SPACE)}, 2007.

\end{thebibliography}

\end{document}
